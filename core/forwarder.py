"""
æ¶ˆæ¯è½¬å‘æ ¸å¿ƒæ¨¡å—

è´Ÿè´£ä» Telegram é¢‘é“è·å–æ¶ˆæ¯å¹¶è½¬å‘åˆ°ç›®æ ‡å¹³å°ï¼ˆTelegram é¢‘é“æˆ– QQ ç¾¤ï¼‰ã€‚
ä¸»è¦åŠŸèƒ½ï¼š
- å®šæœŸæ£€æŸ¥é¢‘é“æ›´æ–°
- æ¶ˆæ¯è¿‡æ»¤ï¼ˆå…³é”®è¯ã€æ­£åˆ™è¡¨è¾¾å¼ï¼‰
- å†·å¯åŠ¨æ”¯æŒï¼ˆä»æŒ‡å®šæ—¥æœŸå¼€å§‹ï¼‰
- åª’ä½“æ–‡ä»¶ä¸‹è½½å’Œå¤„ç†
- å¤šå¹³å°æ¶ˆæ¯å‘é€
"""

import asyncio
import re
import os
import httpx
from datetime import datetime, timezone
from typing import Optional
from telethon.tl.types import Message, PeerUser

from astrbot.api import logger, AstrBotConfig
from ..common.text_tools import clean_telegram_text
from ..common.storage import Storage
from .client import TelegramClientWrapper
from .uploader import FileUploader

MAX_FILE_SIZE = 500 * 1024 * 1024  # 500MB

class Forwarder:
    """
    æ¶ˆæ¯è½¬å‘å™¨æ ¸å¿ƒç±»

    è´Ÿè´£ä» Telegram æºé¢‘é“è·å–æ¶ˆæ¯ï¼Œå¤„ç†åè½¬å‘åˆ°ç›®æ ‡å¹³å°ã€‚
    æ”¯æŒ Telegram-to-Telegram å’Œ Telegram-to-QQ ä¸¤ç§è½¬å‘æ¨¡å¼ã€‚
    """
    def __init__(self, config: AstrBotConfig, storage: Storage, client_wrapper: TelegramClientWrapper, plugin_data_dir: str):
        """
        åˆå§‹åŒ–è½¬å‘å™¨

        Args:
            config: AstrBot é…ç½®å¯¹è±¡ï¼ŒåŒ…å«æºé¢‘é“ã€ç›®æ ‡é¢‘é“ã€è¿‡æ»¤è§„åˆ™ç­‰
            storage: æ•°æ®æŒä¹…åŒ–ç®¡ç†å™¨ï¼Œç”¨äºè®°å½•å·²å¤„ç†çš„æ¶ˆæ¯ID
            client_wrapper: Telegram å®¢æˆ·ç«¯å°è£…
            plugin_data_dir: æ’ä»¶æ•°æ®ç›®å½•ï¼Œç”¨äºä¸´æ—¶å­˜å‚¨ä¸‹è½½çš„åª’ä½“æ–‡ä»¶
        """
        self.config = config
        self.storage = storage
        self.client_wrapper = client_wrapper
        self.client = client_wrapper.client  # å¿«æ·è®¿é—®
        self.plugin_data_dir = plugin_data_dir
        self.proxy_url = config.get("proxy")  # Initialize proxy_url
        self.uploader = FileUploader(self.proxy_url)
        
        # Perform startup cleanup
        self._cleanup_orphaned_files()



    async def check_updates(self):
        """
        æ£€æŸ¥æ‰€æœ‰é…ç½®çš„é¢‘é“æ›´æ–°

        æ‰§è¡Œæµç¨‹ï¼š
        1. æ£€æŸ¥å®¢æˆ·ç«¯è¿æ¥çŠ¶æ€
        2. éå†æ‰€æœ‰é…ç½®çš„æºé¢‘é“
        3. è§£æé¢‘é“é…ç½®ï¼ˆæ”¯æŒæ—¥æœŸè¿‡æ»¤ï¼‰
        4. è°ƒç”¨ _process_channel å¤„ç†æ¯ä¸ªé¢‘é“

        é¢‘é“é…ç½®æ ¼å¼ï¼š
            - "channel_name" - ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹
            - "channel_name|2024-01-01" - ä»æŒ‡å®šæ—¥æœŸå¼€å§‹

        å¼‚å¸¸å¤„ç†ï¼š
            - å•ä¸ªé¢‘é“å¤„ç†å¤±è´¥ä¸å½±å“å…¶ä»–é¢‘é“
            - æ¯ä¸ªé¢‘é“çš„é”™è¯¯ä¼šè¢«è®°å½•æ—¥å¿—
        """
        self.proxy_url = self.config.get("proxy")  # Get proxy from config
        
        # æ£€æŸ¥è¿æ¥çŠ¶æ€
        if not self.client_wrapper.is_connected():
            return

        # è·å–æºé¢‘é“é…ç½®åˆ—è¡¨
        channels_config = self.config.get("source_channels", [])

        # ========== å¹¶è¡Œå¤„ç†æ‰€æœ‰é¢‘é“ ==========
        
        async def process_one(cfg):
            try:
                channel_name = cfg
                start_date = None

                # è§£æé¢‘é“é…ç½®ï¼ˆæ”¯æŒæ—¥æœŸè¿‡æ»¤ï¼‰
                # æ ¼å¼ï¼šchannel_name|YYYY-MM-DD
                if "|" in cfg:
                    channel_name, date_str = cfg.split("|", 1)
                    channel_name = channel_name.strip()
                    try:
                         # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ—¶åŒºæ„ŸçŸ¥çš„ datetime å¯¹è±¡
                         start_date = datetime.strptime(date_str.strip(), "%Y-%m-%d").replace(tzinfo=timezone.utc)
                    except:
                        pass
                else:
                    channel_name = cfg.strip()

                # å¤„ç†è¯¥é¢‘é“
                # logger.debug(f"Start checking {channel_name}...")
                await self._process_channel(channel_name, start_date)
            except Exception as e:
                # è®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†å…¶ä»–é¢‘é“
                logger.error(f"Error checking {cfg}: {e}")

        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = [process_one(cfg) for cfg in channels_config]
        
        # å¹¶å‘æ‰§è¡Œ (Gather all tasks)
        if tasks:
            await asyncio.gather(*tasks)

    async def _process_channel(self, channel_name: str, start_date: Optional[datetime]):
        """
        å¤„ç†å•ä¸ªé¢‘é“çš„æ¶ˆæ¯æ›´æ–°

        Args:
            channel_name: é¢‘é“åç§°æˆ–ID
            start_date: å¯é€‰çš„å¼€å§‹æ—¥æœŸï¼Œç”¨äºå†·å¯åŠ¨æ—¶ä»æŒ‡å®šæ—¥æœŸè·å–æ¶ˆæ¯

        æ‰§è¡Œæµç¨‹ï¼š
        1. åˆå§‹åŒ–æˆ–è·å–é¢‘é“æœ€åå¤„ç†çš„æ¶ˆæ¯ID
        2. å¤„ç†å†·å¯åŠ¨é€»è¾‘ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
        3. è·å–æ–°æ¶ˆæ¯
        4. åº”ç”¨è¿‡æ»¤è§„åˆ™ï¼ˆå…³é”®è¯ã€æ­£åˆ™ï¼‰
        5. é€æ¡è½¬å‘å¹¶æ›´æ–°æŒä¹…åŒ–çŠ¶æ€

        å†·å¯åŠ¨é€»è¾‘ï¼š
            - æœ‰æ—¥æœŸï¼šä»æŒ‡å®šæ—¥æœŸå¼€å§‹è·å–
            - æ— æ—¥æœŸï¼šåªè·å–æœ€æ–°æ¶ˆæ¯IDï¼Œä¸å¤„ç†å†å²
        """
        # ========== åˆå§‹åŒ–é¢‘é“çŠ¶æ€ ==========
        if not self.storage.get_channel_data(channel_name).get("last_post_id"):
             self.storage.update_last_id(channel_name, 0)  # ç¡®ä¿åˆå§‹åŒ–

        last_id = self.storage.get_channel_data(channel_name)["last_post_id"]

        try:
            # ========== å†·å¯åŠ¨å¤„ç† ==========
            if last_id == 0:
                if start_date:
                    # æœ‰æ—¥æœŸé…ç½®ï¼šä»æŒ‡å®šæ—¥æœŸå¼€å§‹è·å–å†å²æ¶ˆæ¯
                    logger.info(f"Cold start for {channel_name} with date {start_date}")
                    pass  # é€»è¾‘åœ¨è¿­ä»£å‚æ•°ä¸­å¤„ç†
                else:
                    # æ— æ—¥æœŸé…ç½®ï¼šè·³è¿‡å†å²ï¼Œåªè®°å½•æœ€æ–°æ¶ˆæ¯ID
                    # è¿™æ ·å¯ä»¥é¿å…é¦–æ¬¡å¯åŠ¨æ—¶è½¬å‘å¤§é‡å†å²æ¶ˆæ¯
                     msgs = await self.client.get_messages(channel_name, limit=1)
                     if msgs:
                         self.storage.update_last_id(channel_name, msgs[0].id)
                         logger.info(f"Initialized {channel_name} at ID {msgs[0].id}")
                     return

            # ========== è·å–æ–°æ¶ˆæ¯ ==========
            new_messages = []

            # æ„å»ºæ¶ˆæ¯è¿­ä»£å‚æ•°
            params = {"entity": channel_name, "reverse": True, "limit": 20}

            if last_id > 0:
                 # å¸¸è§„è¿è¡Œï¼šè·å– ID å¤§äº last_id çš„æ–°æ¶ˆæ¯
                 params["min_id"] = last_id
            elif start_date:
                 # å†·å¯åŠ¨æœ‰æ—¥æœŸï¼šä»è¯¥æ—¥æœŸå¼€å§‹è·å–
                 params["offset_date"] = start_date
            else:
                 # å†·å¯åŠ¨æ— æ—¥æœŸï¼šè·å–å°‘é‡æœ€æ–°æ¶ˆæ¯
                 params["limit"] = 5

            # ä½¿ç”¨è¿­ä»£å™¨è·å–æ¶ˆæ¯ï¼ˆæ”¯æŒåˆ†é¡µï¼Œå†…å­˜å‹å¥½ï¼‰
            async for message in self.client.iter_messages(**params):
                if not message.id: continue
                new_messages.append(message)

            # æ²¡æœ‰æ–°æ¶ˆæ¯åˆ™è¿”å›
            if not new_messages:
                return

            # ========== è·å–è¿‡æ»¤é…ç½® ==========
            filter_keywords = self.config.get("filter_keywords", [])
            filter_regex = self.config.get("filter_regex", "")

            final_last_id = last_id

            # ========== å¤„ç†æ¯æ¡æ¶ˆæ¯ ==========
            
            # ç¼“å†²å¾…å‘é€çš„æ¶ˆæ¯ç»„
            pending_batch = []
            
            async def process_batch(batch):
                if not batch: return
                # è¿‡æ»¤ batch ä¸­çš„æ¶ˆæ¯
                batch_to_send = []
                for msg in batch:
                     try:
                        # ----- ååƒåœ¾ / é¢‘é“è¿‡æ»¤ -----
                        is_user_msg = isinstance(msg.from_id, PeerUser) if msg.from_id else False
                        if not msg.post and is_user_msg: continue

                        text_content = msg.text or ""

                        # ----- å…³é”®è¯è¿‡æ»¤ -----
                        should_skip = False
                        filter_hashtags = self.config.get("filter_hashtags", [])
                        
                        # Hashtag è¿‡æ»¤ (ç²¾ç¡®åŒ¹é…å¸¦ # çš„æ ‡ç­¾)
                        if filter_hashtags:
                            for tag in filter_hashtags:
                                if tag in text_content:
                                    logger.info(f"Filtered {msg.id}: Hashtag {tag}")
                                    should_skip = True
                                    break

                        if not should_skip and filter_keywords:
                            for kw in filter_keywords:
                                if kw in text_content:
                                    logger.info(f"Filtered {msg.id}: Keyword {kw}")
                                    should_skip = True
                                    break
                        
                        # ----- æ­£åˆ™è¡¨è¾¾å¼è¿‡æ»¤ -----
                        if not should_skip and filter_regex:
                            if re.search(filter_regex, text_content, re.IGNORECASE | re.DOTALL):
                                logger.info(f"Filtered {msg.id}: Regex")
                                should_skip = True
                        
                        if not should_skip:
                            batch_to_send.append(msg)
                     except Exception as e:
                         logger.error(f"Error filtering msg {msg.id}: {e}")

                if batch_to_send:
                    try:
                        await self._forward_message(channel_name, batch_to_send)
                        
                        # æ›´æ–° last_id ä¸º batch ä¸­æœ€å¤§çš„ ID
                        max_id = max(m.id for m in batch)
                        self.storage.update_last_id(channel_name, max_id)
                        
                        # é€Ÿç‡é™åˆ¶
                        delay = self.config.get("forward_delay", 0)
                        if delay > 0: await asyncio.sleep(delay)
                    except Exception as e:
                         logger.error(f"Failed to forward batch (first id {batch[0].id}): {e}")


            for msg in new_messages:
                try:
                    # å¦‚æœå½“å‰æ¶ˆæ¯å±äºç›¸å†Œ (æœ‰ grouped_id)
                    if msg.grouped_id:
                        # å¦‚æœç¼“å†²åŒºæœ‰æ¶ˆæ¯ï¼Œä¸”å±äºä¸åŒç»„ -> å…ˆå¤„ç†ç¼“å†²åŒº
                        if pending_batch and pending_batch[0].grouped_id != msg.grouped_id:
                             await process_batch(pending_batch)
                             pending_batch = [] # æ¸…ç©º
                        
                        # åŠ å…¥å½“å‰æ¶ˆæ¯åˆ°ç¼“å†²åŒº
                        pending_batch.append(msg)
                    
                    else:
                        # å½“å‰æ¶ˆæ¯æ˜¯ç‹¬ç«‹çš„
                        # 1. å…ˆå¤„ç†ä¹‹å‰çš„ç¼“å†²åŒº (å¦‚æœæœ‰)
                        if pending_batch:
                             await process_batch(pending_batch)
                             pending_batch = []

                        # 2. ç›´æ¥å¤„ç†å½“å‰æ¶ˆæ¯
                        await process_batch([msg])

                except Exception as e:
                    logger.error(f"Error in msg loop {msg.id}: {e}")
            
            # å¾ªç¯ç»“æŸåï¼Œå¤„ç†å‰©ä½™çš„ç¼“å†²åŒº
            if pending_batch:
                await process_batch(pending_batch)
                
        except Exception as e:
            # é¢‘é“è®¿é—®é”™è¯¯ï¼ˆå¦‚æ— æƒé™ã€é¢‘é“ä¸å­˜åœ¨ç­‰ï¼‰
            logger.error(f"Access error for {channel_name}: {e}")

    async def _forward_message(self, src_channel: str, msgs: list[Message]):
        """
        ç¼–æ’æ¶ˆæ¯è½¬å‘åˆ°æ‰€æœ‰ç›®æ ‡å¹³å° (æ”¯æŒå¤šæ¡æ¶ˆæ¯/ç›¸å†Œ)

        Args:
            src_channel: æºé¢‘é“åç§°
            msgs: Telegram æ¶ˆæ¯å¯¹è±¡åˆ—è¡¨ (å•æ¡æ¶ˆæ¯æˆ–ç›¸å†Œç»„)

        Note:
            æ­¤æ–¹æ³•æ˜¯è½¬å‘é€»è¾‘çš„å…¥å£ç‚¹ï¼ŒæŒ‰é¡ºåºè°ƒç”¨å„å¹³å°è½¬å‘æ–¹æ³•
        """
        await self._forward_to_telegram(src_channel, msgs)
        await self._forward_to_qq(src_channel, msgs)

    async def _forward_to_telegram(self, src_channel: str, msgs: list[Message]):
        """
        è½¬å‘æ¶ˆæ¯åˆ° Telegram ç›®æ ‡é¢‘é“

        Args:
            src_channel: æºé¢‘é“åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            msgs: è¦è½¬å‘çš„æ¶ˆæ¯å¯¹è±¡åˆ—è¡¨

        è½¬å‘æ–¹å¼ï¼š
            ä½¿ç”¨ Telethon çš„ forward_messages æ–¹æ³•ï¼Œæ”¯æŒæ‰¹é‡è½¬å‘
        """
        tg_target = self.config.get("target_channel")
        bot_token = self.config.get("bot_token")

        if not msgs: return

        # åªæœ‰é…ç½®äº†ç›®æ ‡é¢‘é“å’Œ bot_token æ—¶æ‰è½¬å‘
        if tg_target and bot_token:
            try:
                 # ========== è§£æç›®æ ‡é¢‘é“ ==========
                 target = tg_target
                 if isinstance(target, str):
                    if target.startswith("-") or target.isdigit():
                        try:
                            target = int(target)
                        except:
                            pass

                 # è·å–ç›®æ ‡å®ä½“å¹¶è½¬å‘æ¶ˆæ¯
                 entity = await self.client.get_entity(target)
                 await self.client.forward_messages(entity, msgs)
                 logger.info(f"Forwarded {len(msgs)} msgs from {src_channel} to TG")
            except Exception as e:
                 logger.error(f"TG Forward Error: {e}")

    async def _forward_to_qq(self, src_channel: str, msgs: list[Message]):
        """
        è½¬å‘æ¶ˆæ¯åˆ° QQ ç¾¤ (æ”¯æŒåˆå¹¶ç›¸å†Œ)

        Args:
            src_channel: æºé¢‘é“åç§°
            msgs: Telegram æ¶ˆæ¯å¯¹è±¡åˆ—è¡¨

        æ‰§è¡Œæµç¨‹ï¼š
        1. éå†æ‰€æœ‰æ¶ˆæ¯ï¼Œä¸‹è½½åª’ä½“æ–‡ä»¶
        2. åˆå¹¶æ‰€æœ‰æ¶ˆæ¯çš„æ–‡æœ¬å†…å®¹
        3. æ„å»ºå•ä¸€çš„ NapCat æ¶ˆæ¯è½½è·
        4. å‘é€åˆ° QQ ç¾¤
        """
        qq_groups = self.config.get("target_qq_group")
        napcat_url = self.config.get("napcat_api_url")

        if not (qq_groups and napcat_url) or not msgs:
            return
            
        if isinstance(qq_groups, int):
            qq_groups = [qq_groups]
        elif not isinstance(qq_groups, list):
            return

        all_local_files = []
        combined_text_parts = []
        
        try:
            # ========== 1. éå†æ¶ˆæ¯æ”¶é›†å†…å®¹ ==========
            for msg in msgs:
                # æ”¶é›†æ–‡æœ¬ (å»é‡ï¼šå¦‚æœå¤šå¼ å›¾éƒ½æœ‰ç›¸åŒcaptionï¼Œåªä¿ç•™ä¸€ä»½ï¼Ÿæˆ–è€…å…¨éƒ¨æ‹¼æ¥ï¼Ÿ)
                # é€šå¸¸ç›¸å†Œåªæœ‰ç¬¬ä¸€å¼ å›¾æœ‰captionï¼Œæˆ–è€…æ¯å¼ å›¾æœ‰ä¸åŒè¯´æ˜
                # è¿™é‡Œç®€å•ç­–ç•¥ï¼šå…¨éƒ¨æ‹¼æ¥ï¼Œç”¨æ¢è¡Œç¬¦åˆ†éš”
                if msg.text:
                    cleaned = clean_telegram_text(msg.text)
                    if cleaned:
                        combined_text_parts.append(cleaned)

                # ä¸‹è½½åª’ä½“
                files = await self._download_media_safe(msg)
                all_local_files.extend(files)

            # ========== 2. æ„å»ºæœ€ç»ˆæ–‡æœ¬ ==========
            header = f"From #{src_channel}:\n"
            # ç®€å•å»é‡ï¼šå¦‚æœæ‰€æœ‰ text éƒ½ä¸€æ ·ï¼ˆTelegram æœ‰æ—¶ä¼šç»™æ¯å¼ å›¾å¤åˆ¶ç›¸åŒ captionï¼‰ï¼Œåªä¿ç•™ä¸€ä»½
            if len(set(combined_text_parts)) == 1:
                final_body = combined_text_parts[0]
            else:
                final_body = "\n".join(combined_text_parts)
            
            final_text = header + final_body

            # ç©ºå†…å®¹æ£€æŸ¥ (æ—¢æ— æ–‡æœ¬ä¹Ÿæ— æ–‡ä»¶)
            if not final_body and not all_local_files:
                return

            # ========== 3. æ„å»ºæ¶ˆæ¯è½½è· ==========
            message = []
            if final_text.strip():
                 message.append({"type": "text", "data": {"text": final_text}})

            # å¤„ç†æ‰€æœ‰æ”¶é›†åˆ°çš„æ–‡ä»¶
            for fpath in all_local_files:
                file_nodes = await self._process_one_file(fpath)
                if file_nodes:
                    message.extend(file_nodes)
            
            if not message: return

            # ========== 4. å‘é€ ==========
            url = self.config.get("napcat_api_url", "http://127.0.0.1:3000/send_group_msg")
            async with httpx.AsyncClient() as http:
                 for gid in qq_groups:
                     if not gid: continue
                     try:
                        # æ£€æŸ¥æ˜¯å¦æœ‰ record èŠ‚ç‚¹ (è¯­éŸ³ç‰¹æ®Šå¤„ç†)
                        has_record = any(node.get("type") == "record" for node in message)
                        
                        if has_record:
                            # è¯­éŸ³æ‹†åˆ†å‘é€é€»è¾‘ (ç•¥å¾®ç®€åŒ–ï¼Œå‡è®¾ç›¸å†Œé‡Œå¾ˆå°‘æ··è¯­éŸ³)
                            text_nodes = [node for node in message if node.get("type") == "text"]
                            if text_nodes:
                                await http.post(url, json={"group_id": gid, "message": text_nodes}, timeout=30)
                                await asyncio.sleep(1)

                            record_nodes = [node for node in message if node.get("type") == "record"]
                            for rec_node in record_nodes:
                                await http.post(url, json={"group_id": gid, "message": [rec_node]}, timeout=30)
                            
                            logger.info(f"Forwarded album/msg to QQ group {gid} (Split)")
                        else:
                            # æ™®é€š/ç›¸å†Œæ¶ˆæ¯ç›´æ¥å‘é€
                            await http.post(url, json={"group_id": gid, "message": message}, timeout=30)
                            logger.info(f"Forwarded album ({len(msgs)} msgs) to QQ group {gid}")

                     except Exception as e:
                        logger.error(f"Failed to send to QQ group {gid}: {e}")

        except Exception as e:
            logger.error(f"QQ Forward Error: {e}")
        finally:
            # æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
            self._cleanup_files(all_local_files)

    async def _download_media_safe(self, msg: Message) -> list:
        """
        ä¸‹è½½åª’ä½“æ–‡ä»¶ï¼ˆå¸¦å¤§å°æ£€æŸ¥ï¼‰

        Args:
            msg: Telegram æ¶ˆæ¯å¯¹è±¡

        Returns:
            list: ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨

        å®‰å…¨æªæ–½ï¼š
            - æ–‡ä»¶å¤§å°é™åˆ¶ï¼š500MB
            - åªä¸‹è½½å›¾ç‰‡ï¼ˆphotoï¼‰ï¼Œä¸ä¸‹è½½è§†é¢‘/æ–‡æ¡£
            - ä¸‹è½½è¿›åº¦å›è°ƒï¼ˆæ¯20%è¾“å‡ºä¸€æ¬¡ï¼‰

        Note:
            ä¸ºäº†é¿å…ä¸‹è½½å¤§æ–‡ä»¶å¯¼è‡´ç£ç›˜ç©ºé—´æˆ–æ€§èƒ½é—®é¢˜ï¼Œ
            å½“å‰åªæ”¯æŒå›¾ç‰‡ç±»å‹ã€‚å…¶ä»–ç±»å‹ä¼šè·³è¿‡ã€‚
        """
        local_files = []

        # æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦åŒ…å«åª’ä½“
        if not msg.media:
            return local_files

        # ========== æ–‡ä»¶å¤§å°æ£€æŸ¥ ==========
        if hasattr(msg.media, 'document') and hasattr(msg.media.document, 'size'):
            if msg.media.document.size > MAX_FILE_SIZE:
                logger.warning(f"File too large ({msg.media.document.size} bytes), skipping download.")
                return local_files

        # ========== åˆ¤æ–­æ˜¯å¦åº”è¯¥ä¸‹è½½ ==========
        # æ”¯æŒå›¾ç‰‡å’ŒéŸ³é¢‘
        is_photo = hasattr(msg, 'photo') and msg.photo
        is_audio = False
        
        # æ£€æŸ¥éŸ³é¢‘/è¯­éŸ³
        if msg.file and msg.file.mime_type:
            mime = msg.file.mime_type
            if mime.startswith('audio/') or mime == 'application/ogg':
                is_audio = True

        should_download = is_photo or is_audio

        if should_download:
             # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
             def progress_callback(current, total):
                if total > 0:
                    pct = (current / total) * 100
                    # æ¯ 20% è¾“å‡ºä¸€æ¬¡è¿›åº¦ï¼Œé¿å…æ—¥å¿—åˆ·å±
                    if int(pct) % 20 == 0 and int(pct) > 0:
                        logger.info(f"Downloading {msg.id}: {pct:.1f}%")

             # æ‰§è¡Œä¸‹è½½
             try:
                path = await self.client.download_media(
                    msg,
                    file=self.plugin_data_dir,
                    progress_callback=progress_callback
                )
                if path:
                    local_files.append(path)
             except asyncio.CancelledError:
                logger.warning(f"Download cancelled for msg {msg.id}")
                return local_files
             except Exception as e:
                logger.error(f"Download failed for msg {msg.id}: {e}")

        return local_files

    async def _process_one_file(self, fpath: str) -> list:
        """
        å°†æœ¬åœ°æ–‡ä»¶è½¬æ¢ä¸º NapCat æ¶ˆæ¯èŠ‚ç‚¹åˆ—è¡¨

        Args:
            fpath: æ–‡ä»¶è·¯å¾„

        Returns:
            list: NapCat æ¶ˆæ¯èŠ‚ç‚¹åˆ—è¡¨ï¼Œæ¯é¡¹å¦‚ {"type": "image", "data": {...}}

        å¤„ç†ç­–ç•¥ï¼š
            1. å›¾ç‰‡æ–‡ä»¶ï¼ˆ<5MBï¼‰ï¼šä½¿ç”¨ Base64 ç¼–ç ç›´æ¥åµŒå…¥
            2. éŸ³é¢‘æ–‡ä»¶ï¼šä¸Šä¼ åç”Ÿæˆ [è¯­éŸ³æ¶ˆæ¯ + é“¾æ¥]
            3. å…¶ä»–æ–‡ä»¶ï¼šä¸Šä¼ åˆ°æ–‡ä»¶æ‰˜ç®¡æœåŠ¡ï¼ˆå¦‚æœé…ç½®ï¼‰
            4. æ— æ‰˜ç®¡ï¼šè¿”å›æ–‡ä»¶åå ä½ç¬¦
        """
        ext = os.path.splitext(fpath)[1].lower()
        hosting_url = self.config.get("file_hosting_url")

        # ========== 1. å›¾ç‰‡ -> Base64ï¼ˆå°æ–‡ä»¶å®‰å…¨ï¼‰ ==========
        if ext in [".jpg", ".jpeg", ".png", ".webp", ".gif", ".bmp"]:
             # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ŒBase64 å¯¹å¤§æ–‡ä»¶ä¸å‹å¥½
            if os.path.getsize(fpath) < 5 * 1024 * 1024:
                import base64
                with open(fpath, "rb") as image_file:
                    encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
                # NapCat å›¾ç‰‡æ¶ˆæ¯æ ¼å¼
                return [{"type": "image", "data": {"file": f"base64://{encoded_string}"}}]
            else:
                logger.info("Image too large for base64, trying upload...")

        # ========== 2. ä¸Šä¼ åˆ°æ–‡ä»¶æ‰˜ç®¡æœåŠ¡ ==========
        if hosting_url:
            try:
                link = await self.uploader.upload(fpath, hosting_url)
                
                if link:
                    # å¦‚æœæ˜¯éŸ³é¢‘ï¼Œå°è¯•å‘é€è¯­éŸ³é¢„è§ˆ + é“¾æ¥
                    if ext in [".mp3", ".ogg", ".wav", ".m4a", ".flac", ".amr"]:
                            logger.info(f"Audio Link Generated: {link}")
                            return [
                                {"type": "text", "data": {"text": f"\n[Audio: {os.path.basename(fpath)}]\nğŸ”— Link: {link}\n"}},
                                {"type": "record", "data": {"file": link}}
                            ]
                    
                    # æ™®é€šæ–‡ä»¶/å¤§å›¾ç‰‡
                    return [{"type": "text", "data": {"text": f"\n[Media Link: {link}]"}}]
                else:
                     return [{"type": "text", "data": {"text": f"\n[Media File: {os.path.basename(fpath)}] (Upload Failed)"}}]
            except Exception as e:
                 logger.error(f"Upload Error: {type(e).__name__}: {e}")
                 return [{"type": "text", "data": {"text": f"\n[Media File: {os.path.basename(fpath)}] (Upload Failed)"}}]


        # ========== 3. å›é€€æ–¹æ¡ˆ ==========
        # æ— æ‰˜ç®¡æœåŠ¡æ—¶ï¼Œè¿”å›æ–‡ä»¶åå ä½ç¬¦
        fname = os.path.basename(fpath)
        return [{"type": "text", "data": {"text": f"\n[Media File: {fname}] (Too large/No hosting)"}}]

    def _cleanup_files(self, files: list):
        """
        æ¸…ç†ä¸´æ—¶ä¸‹è½½çš„æ–‡ä»¶

        Args:
            files: æ–‡ä»¶è·¯å¾„åˆ—è¡¨

        è¡Œä¸ºï¼š
            - åˆ é™¤æ¯ä¸ªå­˜åœ¨çš„ä¸´æ—¶æ–‡ä»¶
            - é™é»˜å¤„ç†åˆ é™¤å¤±è´¥ï¼ˆæ–‡ä»¶å¯èƒ½å·²è¢«å…¶ä»–è¿›ç¨‹å ç”¨ï¼‰
        """
        for f in files:
            if os.path.exists(f):
                try:
                    os.remove(f)
                except:
                    # åˆ é™¤å¤±è´¥æ—¶é™é»˜å¿½ç•¥ï¼Œä¸ä¸­æ–­æµç¨‹
                    pass

    def _cleanup_orphaned_files(self):
        """
        å¯åŠ¨æ—¶æ¸…ç†æ’ä»¶æ•°æ®ç›®å½•ä¸­çš„å­¤å„¿æ–‡ä»¶
        
        ä¿ç•™æ–‡ä»¶ï¼š
        - data.json (æŒä¹…åŒ–æ•°æ®)
        - user_session.session (Telethon ä¼šè¯)
        - user_session.session-journal (SQLite ä¸´æ—¶æ–‡ä»¶)
        
        åˆ é™¤æ–‡ä»¶ï¼š
        - æ‰€æœ‰å…¶ä»–æ–‡ä»¶ï¼ˆä¸»è¦æ˜¯æ®‹ç•™çš„åª’ä½“æ–‡ä»¶ï¼‰
        """
        if not os.path.exists(self.plugin_data_dir):
            return

        logger.info(f"Cleaning up orphaned files in {self.plugin_data_dir}...")
        
        allowlist = ["data.json", "user_session.session", "user_session.session-journal"]
        deleted_count = 0
        
        try:
            for filename in os.listdir(self.plugin_data_dir):
                if filename in allowlist:
                    continue
                    
                file_path = os.path.join(self.plugin_data_dir, filename)
                
                # åªåˆ é™¤æ–‡ä»¶ï¼Œä¸åˆ é™¤å­ç›®å½•ï¼ˆè™½ç„¶ç°åœ¨æ²¡æœ‰å­ç›®å½•ï¼‰
                if os.path.isfile(file_path):
                    try:
                        os.remove(file_path)
                        deleted_count += 1
                        logger.debug(f"Deleted orphaned file: {filename}")
                    except Exception as e:
                        logger.warning(f"Failed to delete {filename}: {e}")
            
            if deleted_count > 0:
                logger.info(f"Cleanup finished. Removed {deleted_count} orphaned files.")
            else:
                logger.info("Cleanup finished. No orphaned files found.")
                
        except Exception as e:
            logger.error(f"Error during cleanup: {e}")
